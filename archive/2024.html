<!doctype html>
<html lang="en" class="h-100">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="CS Katha Barta">
    <meta name="author" content="Rucha">
    <title>CS Karta Barta | Subhankar Mishra's Lab</title>
    <link href="https://www.niser.ac.in/~smishra/css/smlab.css" rel="stylesheet" type="text/css" />
</head>

<body>
    <div class="container">
        <header class="item">
            <h1>CS Katha Barta | ସଂଗଣକ ବିଜ୍ଞାନ କଥା ବାର୍ତା</h1>
        </header>
        Hosted by <a href="https://www.niser.ac.in/~smishra/"> Subhankar Mishra's Lab</a> <br>
        People -> Rucha Bhalchandra Joshi, Subhankar Mishra
        <hr />
        <h3>CS Katha Barta 2024</h3>
        <h4>Upcoming Talks</h4>
        <ol>
            <!-- <li><strong> <a href="https://sites.google.com/view/vinayakabrol/home">Dr. Vinayak Abrol</a></strong>
                <small>
                    <em> Assistant Professor, CSE IIIT Delhi</em>
                    <ul>
                        <li>Date: Mar 11-15, 2024, hours</li>
                        <li>Title: From Randomness to Trainability in Deep Neural Networks</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> TBA </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li> -->


            <li><strong>Dr. Thiparat Chotibut (Thip)</strong>
                <small>
                    <em> <a href="https://www.chics.ai">Chula Intelligent and Complex Systems Lab</a>, Chulalongkorn
                        University</em>
                    <ul>
                        <li>Date: Apr 18, 2024, 09:30 hours</li>
                        <li>Title: From explainable NLP to quantum dynamics prediction: A two-way synergy between many-body quantum physics and temporal machine learning models</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> In this talk, we will discuss our recent work that highlights the fruitful interplay
                                    between many-body quantum physics and temporal machine learning models. The first
                                    part, "Quantum Meets Language," employs techniques from many-body quantum physics to
                                    enhance explainability in the common natural language processing task of sentiment
                                    analysis. We will examine how transforming a recurrent neural network model into its
                                    matrix product states counterpart can inform design principles and facilitate
                                    interpretable predictions in machine learning models for sentiment analysis [1]. The
                                    second part, "Forecasting Many-Body Quantum Dynamics with Machine Learning," delves
                                    into our data-driven approach that uses a variant of reservoir computing to
                                    accurately predict complex quantum many-body dynamics far into the future,
                                    circumventing the need for computing intermediate time steps that typically slow
                                    down classical simulations of such dynamics [2]. These findings not only demonstrate
                                    the capabilities of GPUs in advancing scientific research but also underscore the
                                    potential of these interdisciplinary approaches to research in AI, materials
                                    science, and quantum simulation. 
                                    
                                    References:
                                    [1] J. Tangpanitanon et al, Explainable Natural Language Processing with Matrix Product States, New Journal of Physics, 24 053032, 2022   
                                    [2] A. Sornsaeng et al, Quantum Next Generation Reservoir Computing: An Efficient Quantum Algorithm for Predicting Quantum Dynamics  
https://doi.org/10.48550/arXiv.2308.14239
                                    </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>


            <!-- <li><strong>Dr. Saket Anand</strong>
                <small>
                    <em> Associate Professor IIIT Delhi</em>
                    <ul>
                        <li>Date: April 8-12, 2024 </li>
                        <li>Title: TBA</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> TBA </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li> -->
            <li><strong>Dr. Vinod Kurmi</strong>
                <small>
                    <em> Assistant Professor, IISER Bhopal</em>
                    <ul>
                        <li>Date: April 19, 2024, 10:30 hours </li>
                        <li>Title: Deep Fair Learning</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> Deep neural networks trained on biased data often inadvertently learn unintended
                                    inference rules, particularly when labels are strongly correlated with biased
                                    features. While several approaches have been proposed, one view towards mitigating
                                    bias is through adversarial learning. The main drawback of the adversarial method is
                                    that it directly introduces a tradeoff with accuracy, as the features that the
                                    discriminator deems to be sensitive to discrimination or bias could be correlated
                                    with classification. In our work we show that a biased discriminator can actually be
                                    used to improve this bias-accuracy tradeoff. Specifically, this is achieved by using
                                    a feature masking approach using the discriminator's gradients. We ensure that the
                                    features favored for the bias discrimination are de-emphasized and the unbiased
                                    features are enhanced during classification.
                                    One issue with these methods is that they address bias indirectly in the feature or
                                    sample space, with no control over learned weights, making it difficult to control
                                    the bias propagation across different layers. Based on this observation, we
                                    introduce a novel approach to address bias directly in the model's parameter space,
                                    preventing its propagation across layers. Our method involves training two models: a
                                    bias model for biased features and a debias model for unbiased details, guided by
                                    the bias model. We enforce dissimilarity in the debias model's later layers and
                                    similarity in its initial layers with the bias model, ensuring it learns unbiased
                                    low-level features without adopting biased high-level abstractions. By incorporating
                                    this explicit constraint during training, our approach shows enhanced classification
                                    accuracy and debiasing effectiveness across various synthetic and real-world
                                    datasets of different sizes. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong> <a href="https://kracr.iiitd.edu.in/">Dr. Raghava Mutharaju</a></strong>
                <small>
                    <em> Assistant Professor, CSE IIIT Delhi</em>
                    <ul>
                        <li>Date: April 19, 2024, 14:30 hours</li>
                        <li>Title: Applications of Symbolic and Neuro-Symbolic AI</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> Heterogeneous data from different sources are often related to each other. In order to derive value, the data should be integrated, structured, and the relationships should be made explicit. Knowledge Graphs (KG) can play a key role in achieving these goals. In the first part of the talk, after briefly introducing Knowledge Graphs and Ontologies, I will discuss two use cases that make use of KGs. In the second part of the talk, I will discuss the advantages of combining the neural and the symbolic aspects of AI through two use cases. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>


        </ol>
        <h4>Past Talks</h4>
        <ol reversed>
            <li><strong>Dr. Pawan Goyal</strong>
                <small>
                    <em> Associate Professor IIT Kharagpur</em>
                    <ul>
                        <li>Date: Mar 20, 2024, 18:00 hours</li>
                        <li>Title: Sanskrit and Computational Linguistics</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> The talk will focus on how to make Sanskrit manuscripts more accessible to end-users
                                    through natural language technologies. The morphological richness, compounding, free
                                    word orderliness, and low-resource nature of Sanskrit pose significant challenges
                                    for developing deep learning solutions. We identify fundamental tasks, which are
                                    crucial for developing a robust NLP technology for Sanskrit: word segmentation,
                                    morphological parsing, dependency parsing, syntactic linearisation.

                                    Next, we will present our framework using Energy Based Models for multiple
                                    structured prediction tasks in Sanskrit. Our framework expects a graph as input,
                                    where relevant linguistic information is encoded in the nodes, and the edges are
                                    then used to indicate the association between these nodes. Typically the state of
                                    the art models for morphosyntactic tasks in morphologically rich languages still
                                    rely on hand-crafted features for their performance. But here, we automate the
                                    learning of the feature function. The feature function so learnt along with the
                                    search space we construct, encodes relevant linguistic information for the tasks we
                                    consider. This enables us to substantially reduce the training data requirements to
                                    as low as 10% as compared to the data requirements for the neural state of the art
                                    models.

                                    Finally, the talk will also discuss some recent works which make use of the latest
                                    advances in deep learning for Sanskrit NLP, as well as interesting future directions
                                    in the field of Sanskrit Computational Linguistics. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong> <a href="https://dcll.iiitd.edu.in">Bapi Chatterjee</a></strong>
                <small>
                    <em> Assistant Professor, CSE IIIT Delhi</em>
                    <ul>
                        <li>Date: Mar 14, 2024, 09:30 hours</li>
                        <li>Title: Dynamics of auxiliary parameters in distributed machine learning</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> Distributed systems are at the center stage of training today's machine learning
                                    models. Such settings include shared-memory and message-passing asynchrony,
                                    compression of gradients, local training to reduce communication, and combinations
                                    thereof. With problem-specific assumptions such as non-convexity and non-smoothness
                                    in place, taming the convergence of iterates under such system-dependent
                                    inconsistencies becomes challenging. In this talk, we present several algorithms
                                    with various system- and problem-generated analytical assumptions. We discuss a
                                    general strategy for constructing these algorithms drawing from their convergence
                                    theory. We discuss constructing an auxiliary global parameter in every case. We show
                                    that convergence of the distributed machine learning training algorithm can be
                                    tracked via the dynamics of the constructed parameter. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong>Dr. Nidhi Tiwari</strong>
                <small>
                    <em>Microsoft, India</em>
                    <ul>
                        <li>Date: Jan 29, 2024, 13:30 hours</li>
                        <li>Title: Leveraging Open-Source Foundation models to develop intelligent applications
                            <a href="https://www.youtube.com/watch?v=YFFANHxUy_E">Youtube</a>
                        </li>
                        <li>
                            <details>
                                <summary> Abstract</summary>
                                <p> OpenAI ChatGPT and other foundation models have garnered widespread attention
                                    with their ability to respond effectively to a wide range of human questions,
                                    solving logical problems, providing reasoning for the solutions, generate images and
                                    so on. We all want to explore their capabilities and utilize them for developing
                                    intelligent features/products. However, we are constrained and delayed due the high
                                    cost, low training data, limited access and large size. The increasing number and
                                    variety of Open-source foundation models are good alternative for this. In this
                                    session we will look at some of the open source LLMs. We will touch upon a few ways
                                    to access, finetune and use them for projects. We will also look at some options
                                    that enable integration of LLMs in mobile applications. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong>Dr. Amit Chintamani Awekar</strong>
                <small>
                    <em>Associate Professor, IIT Guwahati</em>
                    <ul>
                        <li>Date: Jan 25, 2024, 09:30 hours </li>
                        <li>Title: Addressing the data bottleneck in information extraction</li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> Supervised Machine Learning tasks require annotated data for model
                                    training. Annotating large-scale data is both costly and error-prone.
                                    The annotation error issue becomes even more complex when the
                                    number of annotation labels is of the order of hundreds or thousands.
                                    As a result, absence of high-quality data becomes the real bottleneck
                                    in improving the model performance. In this talk, we will consider
                                    three scenarios for addressing the data bottleneck.
                                <ol>
                                    <li>Data annotations are noisy. However, we cannot afford to re-
                                        annotate the whole dataset. How do we re-annotate only a part
                                        of the data?</li>
                                    <li>The annotation labels fail to capture the fine semantics of data.
                                        How do we create new annotation labels that are appropriate
                                        for our task?</li>
                                    <li>None of the existing datasets are appropriate for our particular
                                        application. How do we create new datasets from scratch or
                                        merge multiple existing datasets?</li>
                                </ol>
                                We will discuss these three scenarios in the context of a specific task
                                of Information Extraction. It is the task of extracting structured
                                information from unstructured natural language text. </p>
                            </details>
                        </li>
                    </ul>
                </small>
            </li>
            <li><strong>Prof. Animesh Mukherjee</strong>
                <small>
                    <em>Professor, IIT Kharagpur</em>
                    <ul>
                        <li>Date: Jan 10, 2024, 08:30 hours</li>
                        <li>Title: Vulnerabilities of LLMs in hate speech detection
                            <a href="https://www.youtube.com/watch?v=oZA_G6KH-2A">Youtube</a>
                        </li>
                        <li>
                            <details>
                                <summary>Abstract</summary>
                                <p> Recently efforts have been made by social media platforms as well as researchers to
                                    detect hateful or toxic language using large language models. However, none of these
                                    works aim to use explanation, additional context and victim community information in
                                    the detection process. We utilise different prompt variation, input information and
                                    evaluate large language models in zero shot setting (without adding any in-context
                                    examples). We select two large language models (GPT-3.5 and text-davinci) and three
                                    datasets - HateXplain, implicit hate and ToxicSpans. We find that on average
                                    including the target information in the pipeline improves the model performance
                                    substantially (∼20-30%) over the baseline across the datasets. There is also a
                                    considerable effect of adding the rationales/explanations into the pipeline
                                    (∼10-20%) over the baseline across the datasets. In addition, we further provide a
                                    typology of the error cases where these large language models fail to (i) classify
                                    and (ii) explain the reason for the decisions they take. Such vulnerable points
                                    automatically constitute ‘jailbreak’ prompts for these models and industry scale
                                    safeguard techniques need to be developed to make the models robust against such
                                    prompts. 
                                
                                    </p>
                                   
                            </details>
                        </li>
                    </ul>
                </small>
            </li>



        </ol>
        <hr />
        <h3><a href="https://www.niser.ac.in/~smishra/event/cskathabarta/">CS Katha Barta</a> Past years</h3>
        <ul>
            <li><a href="https://www.niser.ac.in/~smishra/event/cskathabarta/archive/2023.html">2023</a></li>
            <li><a href="https://www.niser.ac.in/~smishra/event/cskathabarta/archive/2022.html">2022</a></li>
            <li><a href="https://www.niser.ac.in/~smishra/event/cskathabarta/archive/2021.html">2021</a></li>
        </ul>
        <hr />
        <br> <br>
        <div class="navbar">
            <a href="https://www.niser.ac.in/~smishra/index.html">Home</a>
            <a href="https://www.niser.ac.in/~smishra/people.html">People</a>
            <a href="https://www.niser.ac.in/~smishra/research.html">Research</a>
            <a href="https://www.niser.ac.in/~smishra/teaching.html">Teaching</a>
            <a href="https://www.niser.ac.in/~smishra/events.html" class="active">Events</a>
        </div>
</body>